log.train + 1
log.train
test.data %>% select(where(is.numeric)) %>% . + 1
test.data %>% select(where(is.numeric)) %>% + 1
tmp <- train.data %>% select(where(is.numeric))
fctrs <- train.data %>% select(!where(is.numeric))
log(tmp + 1)
tmp <- train.data %>% select(where(is.numeric))
fctrs <- train.data %>% select(!where(is.numeric))
train <- cbind(log(tmp + 1), fctrs)
tmp.test  <- test.data %>% select(where(is.numeric))
fctrs <- test.data %>% select(!where(is.numeric))
test <- cbind(log(tmp.test  + 1), fctrs)
dmy.train <- model.matrix(as.formula(paste("Responder ~.")),data=train)
dmy.train <- dmy.train[,-1] # remove intercept
# dummy encoding of factors with model.matrix for test set
dmy.test <- model.matrix(as.formula(paste("Responder ~.")),data=test)
dmy.test <- dmy.test[,-1] # remove intercept
any(is.infinite(train))
is.infinite(train)
test
train
tmp.train <- train.data %>% select(where(is.numeric))
fctrs <- train.data %>% select(!where(is.numeric))
train <- data.frame(cbind(log(tmp.train  + 1), fctrs))
# transform testing data
tmp.test  <- test.data %>% select(where(is.numeric))
fctrs <- test.data %>% select(!where(is.numeric))
test <- data.frame(cbind(log(tmp.test  + 1), fctrs))
<- data.frame(cbind(log(tmp.train  + 1), fctrs))
train
any(is.infinite(train))
class(train)
dmy.train <- model.matrix(as.formula(paste("Responder ~.")),data=train)
dmy.train <- dmy.train[,-1] # remove intercept
# dummy encoding of factors with model.matrix for test set
dmy.test <- model.matrix(as.formula(paste("Responder ~.")),data=test)
dmy.test <- dmy.test[,-1] # remove intercept
any(is.infinite(dmy.train))
any(is.infinite(dmy.test)
any(is.infinite(dmy.test))
any(is.infinite(dmy.test))
test
a <- seq(0.1, 0.9, 0.05)
search <- foreach(i = a, .combine = rbind) %dopar% {
cv <- cv.glmnet(dmy.train, train$Responder,type.measure = "auc", family = "binomial", nfold = 10,  parallel = TRUE, alpha = 1)
data.frame(cvm = cv$cvm[cv$lambda == cv$lambda.1se], lambda.1se = cv$lambda.1se, alpha = i)
}
warnings(9)
warnings()
a <- seq(0.1, 0.9, 0.05)
search <- foreach(i = a, .combine = rbind) %dopar% {
cv <- cv.glmnet(dmy.train, train$Responder,type.measure = "auc", family = "binomial", nfold = 5,  parallel = TRUE, alpha = 1)
data.frame(cvm = cv$cvm[cv$lambda == cv$lambda.1se], lambda.1se = cv$lambda.1se, alpha = i)
}
warnings()
a <- seq(0.1, 0.9, 0.05)
search <- foreach(i = a, .combine = rbind) %dopar% {
cv <- cv.glmnet(dmy.train, train$Responder,type.measure = "deviance", family = "binomial", nfold = 5,  parallel = TRUE, alpha = 1)
data.frame(cvm = cv$cvm[cv$lambda == cv$lambda.1se], lambda.1se = cv$lambda.1se, alpha = i)
}
cv3 <- search[search$cvm == min(search$cvm), ]
md3 <- glmnet(x, dat3$Responder, family = "binomial", lambda = cv3$lambda.1se, alpha = cv3$alpha)
cv3$lambda.1se
cv3$alpha
md3 <- glmnet(dmy.train, train$Responder, family = "binomial", lambda = cv3$lambda.1se, alpha = cv3$alpha)
coef(md3)
coef(md3)
md3 %>% predict(test)
test
md3 %>% predict(dmy.test)
train$Responder
md3 %>% predict(dmy.test, class = "probabilities")
?predict
md3
dmy.test
md3 %>% predict(dmy.test)
data("PimaIndiansDiabetes2", package = "mlbench")
PimaIndiansDiabetes2 <- na.omit(PimaIndiansDiabetes2)
# Inspect the data
sample_n(PimaIndiansDiabetes2, 3)
# Split the data into training and test set
set.seed(123)
training.samples <- PimaIndiansDiabetes2$diabetes %>%
createDataPartition(p = 0.8, list = FALSE)
train.data  <- PimaIndiansDiabetes2[training.samples, ]
test.data <- PimaIndiansDiabetes2[-training.samples, ]
install.packages("mlbench")
data("PimaIndiansDiabetes2", package = "mlbench")
PimaIndiansDiabetes2 <- na.omit(PimaIndiansDiabetes2)
# Inspect the data
sample_n(PimaIndiansDiabetes2, 3)
# Split the data into training and test set
set.seed(123)
training.samples <- PimaIndiansDiabetes2$diabetes %>%
createDataPartition(p = 0.8, list = FALSE)
train.data  <- PimaIndiansDiabetes2[training.samples, ]
test.data <- PimaIndiansDiabetes2[-training.samples, ]
train.data
test.data
x <- model.matrix(diabetes~., train.data)[,-1]
# Convert the outcome (class) to a numerical variable
y <- ifelse(train.data$diabetes == "pos", 1, 0)
x
dmy.train <- model.matrix(Responder~.,data=train)[,-1]
dmy.train
y <- ifelse(train.data$diabetes == "pos", 1, 0)
y
y <- ifelse(train$Responder == "pos", 1, 0)
y
y <- ifelse(train$Responder == "ja", 1, 0)
y
a <- seq(0.1, 0.9, 0.05)
search <- foreach(i = a, .combine = rbind) %dopar% {
cv <- cv.glmnet(dmy.train, y,type.measure = "deviance", family = "binomial", nfold = 5,  parallel = TRUE, alpha = 1)
data.frame(cvm = cv$cvm[cv$lambda == cv$lambda.1se], lambda.1se = cv$lambda.1se, alpha = i)
}
cv3 <- search[search$cvm == min(search$cvm), ]
md3 <- glmnet(dmy.train, y, family = "binomial", lambda = cv3$lambda.1se, alpha = cv3$alpha)
coef(md3)
a <- seq(0.1, 0.9, 0.05)
search <- foreach(i = a, .combine = rbind) %dopar% {
cv <- cv.glmnet(dmy.train, y,type.measure = "deviance", family = "binomial", nfold = 5,  parallel = TRUE, alpha = 1)
data.frame(cvm = cv$cvm[cv$lambda == cv$lambda.1se], lambda.1se = cv$lambda.1se, alpha = i)
}
cv3 <- search[search$cvm == min(search$cvm), ]
md3 <- glmnet(dmy.train, y, family = "binomial", lambda = cv3$lambda.1se, alpha = cv3$alpha)
coef(md3)
a <- seq(0.1, 0.9, 0.05)
search <- foreach(i = a, .combine = rbind) %dopar% {
cv <- cv.glmnet(dmy.train, y,type.measure = "deviance", family = "binomial", nfold = 5,  parallel = TRUE, alpha = 1)
data.frame(cvm = cv$cvm[cv$lambda == cv$lambda.1se], lambda.1se = cv$lambda.1se, alpha = i)
}
cv3 <- search[search$cvm == min(search$cvm), ]
md3 <- glmnet(dmy.train, y, family = "binomial", lambda = cv3$lambda.1se, alpha = cv3$alpha)
coef(md3)
set.seed(25)
a <- seq(0.1, 0.9, 0.05)
search <- foreach(i = a, .combine = rbind) %dopar% {
cv <- cv.glmnet(dmy.train, y,type.measure = "deviance", family = "binomial", nfold = 5,  parallel = TRUE, alpha = 1)
data.frame(cvm = cv$cvm[cv$lambda == cv$lambda.1se], lambda.1se = cv$lambda.1se, alpha = i)
}
cv3 <- search[search$cvm == min(search$cvm), ]
md3 <- glmnet(dmy.train, y, family = "binomial", lambda = cv3$lambda.1se, alpha = cv3$alpha)
coef(md3)
set.seed(25)
a <- seq(0.1, 0.9, 0.05)
search <- foreach(i = a, .combine = rbind) %dopar% {
cv <- cv.glmnet(dmy.train, y,type.measure = "deviance", family = "binomial", nfold = 5,  parallel = TRUE, alpha = 1)
data.frame(cvm = cv$cvm[cv$lambda == cv$lambda.1se], lambda.1se = cv$lambda.1se, alpha = i)
}
cv3 <- search[search$cvm == min(search$cvm), ]
md3 <- glmnet(dmy.train, y, family = "binomial", lambda = cv3$lambda.1se, alpha = cv3$alpha)
coef(md3)
model.matrix(Responder~.,data=train)[,-1]
model.matrix(Responder~.,data=test)[,-1]
x.train <- model.matrix(Responder~.,data=train)[,-1]
y.train <- ifelse(train$Responder == "ja", 1, 0)
# dummy encoding of factors with model.matrix for test set
x.test <- model.matrix(Responder~.,data=test)[,-1]
y.test <- ifelse(test$Responder == "ja", 1, 0)
x.train <- model.matrix(Responder~.,data=train)[,-1]
y.train <- ifelse(train$Responder == "ja", 1, 0)
# dummy encoding of factors with model.matrix for test set
x.test <- model.matrix(Responder~.,data=test)[,-1]
y.test <- ifelse(test$Responder == "ja", 1, 0)
set.seed(25)
a <- seq(0.1, 0.9, 0.05)
search <- foreach(i = a, .combine = rbind) %dopar% {
cv <- cv.glmnet(x.train, y.train,type.measure = "deviance", family = "binomial", nfold = 5,  parallel = TRUE, alpha = 1)
data.frame(cvm = cv$cvm[cv$lambda == cv$lambda.1se], lambda.1se = cv$lambda.1se, alpha = i)
}
cv3 <- search[search$cvm == min(search$cvm), ]
md3 <- glmnet(x.train, y.train, family = "binomial", lambda = cv3$lambda.1se, alpha = cv3$alpha)
coef(md3)
md3 %>% predict(x.test)
md3 %>% predict(x.train)
train$Responder
x.train <- model.matrix(Responder~.,data=train)[,-1]
y.train <- train$Responder
# dummy encoding of factors with model.matrix for test set
x.test <- model.matrix(Responder~.,data=test)[,-1]
y.test <- test$Responder
set.seed(25)
a <- seq(0.1, 0.9, 0.05)
search <- foreach(i = a, .combine = rbind) %dopar% {
cv <- cv.glmnet(x.train, y.train,type.measure = "deviance", family = "binomial", nfold = 5,  parallel = TRUE, alpha = 1)
data.frame(cvm = cv$cvm[cv$lambda == cv$lambda.1se], lambda.1se = cv$lambda.1se, alpha = i)
}
cv3 <- search[search$cvm == min(search$cvm), ]
md3 <- glmnet(x.train, y.train, family = "binomial", lambda = cv3$lambda.1se, alpha = cv3$alpha)
coef(md3)
md3 %>% predict(x.test)
data("PimaIndiansDiabetes2", package = "mlbench")
PimaIndiansDiabetes2 <- na.omit(PimaIndiansDiabetes2)
# Inspect the data
sample_n(PimaIndiansDiabetes2, 3)
# Split the data into training and test set
set.seed(123)
training.samples <- PimaIndiansDiabetes2$diabetes %>%
createDataPartition(p = 0.8, list = FALSE)
train.data  <- PimaIndiansDiabetes2[training.samples, ]
test.data <- PimaIndiansDiabetes2[-training.samples, ]
x <- model.matrix(diabetes~., train.data)[,-1]
# Convert the outcome (class) to a numerical variable
y <- ifelse(train.data$diabetes == "pos", 1, 0)
set.seed(123)
cv.lasso <- cv.glmnet(x, y, alpha = 1, family = "binomial")
# Fit the final model on the training data
model <- glmnet(x, y, alpha = 1, family = "binomial",
lambda = cv.lasso$lambda.min)
coef(model)
x.test <- model.matrix(diabetes ~., test.data)[,-1]
model %>% predict(newx = x.test)
probabilities <- model %>% predict(newx = x.test)
predicted.classes <- ifelse(probabilities > 0.5, "pos", "neg")
predicted.classes
y.test
probabilities <- md3 %>% predict(newx = x.test)
predicted.classes <- ifelse(probabilities > 0.5, "pos", "neg")
probabilities <- md3 %>% predict(newx = x.test)
set.seed(25)
a <- seq(0.1, 0.9, 0.05)
search <- foreach(i = a, .combine = rbind) %dopar% {
cv <- cv.glmnet(x.train, y.train,type.measure = "deviance", family = "binomial", nfold = 5,  parallel = TRUE, alpha = 1)
data.frame(cvm = cv$cvm[cv$lambda == cv$lambda.1se], lambda.1se = cv$lambda.1se, alpha = i)
}
cv3 <- search[search$cvm == min(search$cvm), ]
md3 <- glmnet(x.train, y.train, family = "binomial", lambda = cv3$lambda.1se, alpha = cv3$alpha)
coef(md3)
x.train <- model.matrix(Responder~.,data=train)[,-1]
y.train <- train$Responder
# dummy encoding of factors with model.matrix for test set
x.test <- model.matrix(Responder~.,data=test)[,-1]
y.test <- test$Responder
probabilities <- md3 %>% predict(newx = x.test)
predicted.classes <- ifelse(probabilities > 0.5, "pos", "neg")
observed.classes <- y.test
mean(predicted.classes == observed.classes)
predicted.classes
observed.classes
probabilities <- md3 %>% predict(newx = x.test)
predicted.classes <- ifelse(probabilities > 0.5, "ja", "nein")
# Model accuracy
observed.classes <- y.test
mean(predicted.classes == observed.classes)
observed.classes
predicted.classes
set.seed(849)
md <- train(x, dat3$Responder, method = "glmnet",
trControl = cctrl1,metric = "ROC",tuneGrid = expand.grid(alpha = seq(0,1,0.1),
lambda = seq(0.001,0.2,by = 0.001)))
cctrl1 <- trainControl(method="cv", number=10, returnResamp="all",
#preProcess(c("center","scale"),
classProbs=TRUE, summaryFunction=twoClassSummary)
set.seed(849)
md <- train(x.train, y.train, method = "glmnet",
trControl = cctrl1,metric = "ROC",tuneGrid = expand.grid(alpha = seq(0,1,0.1),
lambda = seq(0.001,0.2,by = 0.001)))
md
max(md$results$ROC)
coef(md$finalModel, md$finalModel$lambdaOpt)
md %>% predict(x.test)
y.train
obs <- y.test
y.test
mean(pred == obs)
pred <- md %>% predict(x.test)
obs <- y.test
mean(pred == obs)
ROC(pred, obs)
roc(category, prediction)
library(pROC)
roc(obs, pred)
pred
pred <- md %>% predict(x.test, class = "prob")
pred
pred <- md %>% predict(x.test, type = "prob")
pred
roc_obj <- roc(obs, pred$ja)
roc_obj
auc(roc_obj)
cctrl1 <- trainControl(method="cv", number=10, returnResamp="all",
preProcess(c("center","scale"),
classProbs=TRUE, summaryFunction=twoClassSummary)
# define ctrl function
cctrl1 <- trainControl(method="cv", number=10, returnResamp="all",
preProcess(c("center","scale")),
classProbs=TRUE, summaryFunction=twoClassSummary)
cctrl1 <- trainControl(method="cv", number=10, returnResamp="all",
preProcess(c("center","scale")),
classProbs=TRUE, summaryFunction=twoClassSummary)
cctrl1 <- trainControl(method="cv", number=10, returnResamp="all",
preProcess(c("center","scale")),
classProbs=TRUE, summaryFunction=twoClassSummary)
cctrl1 <- trainControl(method="cv", number=10, returnResamp="all",
classProbs=TRUE, summaryFunction=twoClassSummary)
set.seed(849)
md <- train(x.train, y.train, method = "glmnet",preProcess = c("center","scale"),
trControl = cctrl1,metric = "ROC",tuneGrid = expand.grid(alpha = seq(0,1,0.1),
lambda = seq(0.001,0.2,by = 0.001)))
max(md$results$ROC)
coef(md$finalModel, md$finalModel$lambdaOpt)
pred <- md %>% predict(x.test, type = "prob")
obs <- y.test
roc_obj <- roc(obs, pred$ja)
auc(roc_obj)
roc_obj <- roc(obs, pred$nein)
auc(roc_obj)
dat_fct
resample <- sample(dat_fct, replace = TRUE)
resample
dat <- load_melanoma_data() %>%
filter(!is.na(Responder)) # n = 81
dat_fct <- dat %>%
filter(miRExpAssess == 1) %>%
select(-c(TRIM_PDL1_Expression , miRExpAssess, therapy_at_blood_draw)) %>%
mutate( across(c(Responder, Stadium, Baseline, BRAF, ECOG, subtype, localization,
sex, Hirnmetastase, adjuvant_IFN, befallen_Organe, nras), as.factor))
dat_fct$ECOG <- NULL
dat_fct$subtype <- NULL
dat_fct$localization <- NULL
dat_fct$nras <- NULL
dat_fct$Baseline <- NULL
resample <- sample(dat_fct, replace = TRUE)
resample
dat_fct
sample(dat_fct, replace = TRUE)
?sample
sample(dat_fct, replace = TRUE)
sample(dat_fct, replace = TRUE)
resample <- sample(dat_fct, replace = TRUE)
resample %>% names()
resample %>% names() %>% unique()
resample %>% names() %>% unique() %>% length()
t(dat_fct)
sample(t(dat_fct), replace = TRUE)
nrow(dat_fct)
sample(nrow(dat_fct))
sample(nrow(dat_fct)) %>% unique(9)
sample(nrow(dat_fct)) %>% unique()
sample(nrow(dat_fct)) %>% unique() %>% length()
sample(nrow(dat_fct), replace = TRUE)
sample(nrow(dat_fct), replace = TRUE) %>% unique()
sample(nrow(dat_fct), replace = TRUE) %>% unique() %>% length()
resample <- dat_fct[sample(nrow(dat_fct), replace = TRUE), ]
resample
resample$ID %>% unique()
resample$ID %>% unique() %>% length()
set.seed(4)
resample <- dat_fct[sample(nrow(dat_fct), replace = TRUE), ]
set.seed(123)
ind.train <- createDataPartition(dat_fct$Responder, p = 0.7, list = FALSE)
ind.train
resample <- dat_fct[sample(nrow(dat_fct), replace = TRUE), ]
# define test and training set
set.seed(123)
ind.train <- createDataPartition(resample$Responder, p = 0.7, list = FALSE)
train.data  <- resample[ind.train, ]
test.data <- resample[-ind.train, ]
# transform training data
tmp.train <- train.data %>% select(where(is.numeric))
fctrs <- train.data %>% select(!where(is.numeric))
train <- data.frame(cbind(log(tmp.train  + 1), fctrs))
# transform testing data
tmp.test  <- test.data %>% select(where(is.numeric))
fctrs <- test.data %>% select(!where(is.numeric))
test <- data.frame(cbind(log(tmp.test  + 1), fctrs))
# dummy encoding of factors with model.matrix
x.train <- model.matrix(Responder~.,data=train)[,-1]
y.train <- train$Responder
# dummy encoding of factors with model.matrix for test set
x.test <- model.matrix(Responder~.,data=test)[,-1]
y.test <- test$Responder
set.seed(4)
resample <- dat_fct[sample(nrow(dat_fct), replace = TRUE), ]
# define test and training set
set.seed(123)
ind.train <- createDataPartition(resample$Responder, p = 0.7, list = FALSE)
train.data  <- resample[ind.train, ]
test.data <- resample[-ind.train, ]
# transform training data
tmp.train <- train.data %>% select(where(is.numeric))
fctrs <- train.data %>% select(!where(is.numeric))
train <- data.frame(cbind(log(tmp.train  + 1), fctrs))
# transform testing data
tmp.test  <- test.data %>% select(where(is.numeric))
fctrs <- test.data %>% select(!where(is.numeric))
test <- data.frame(cbind(log(tmp.test  + 1), fctrs))
# dummy encoding of factors with model.matrix
x.train <- model.matrix(Responder~.,data=train)[,-1]
y.train <- train$Responder
# dummy encoding of factors with model.matrix for test set
x.test <- model.matrix(Responder~.,data=test)[,-1]
y.test <- test$Responder
cl <- makeCluster(detectCores(), type='PSOCK')
registerDoParallel(cl)
# define ctrl function
cctrl1 <- trainControl(method="cv", number=10, returnResamp="all",
classProbs=TRUE, summaryFunction=twoClassSummary)
# run glmnet model
set.seed(849)
md <- train(x.train, y.train, method = "glmnet",preProcess = c("center","scale"),
trControl = cctrl1,metric = "ROC",tuneGrid = expand.grid(alpha = seq(0,1,0.1),
lambda = seq(0.001,0.2,by = 0.001)))
x.train
train.data
tmp.train <- train.data %>% select(where(is.numeric))
fctrs <- train.data %>% select(!where(is.numeric))
train <- data.frame(cbind(log(tmp.train  + 1), fctrs))
train
dat <- load_melanoma_data() %>%
filter(!is.na(Responder)) # n = 81
dat_fct <- dat %>%
filter(miRExpAssess == 1) %>%
select(-c(TRIM_PDL1_Expression , miRExpAssess, therapy_at_blood_draw)) %>%
mutate( across(c(Responder, Stadium, Baseline, BRAF, ECOG, subtype, localization,
sex, Hirnmetastase, adjuvant_IFN, befallen_Organe, nras), as.factor))
dat_fct$ECOG <- NULL
dat_fct$subtype <- NULL
dat_fct$localization <- NULL
dat_fct$nras <- NULL
dat_fct$Baseline <- NULL
dat_fct$ID <- NULL
#####################################
##
## 1.a Imputation of missing values
##
#####################################
# detect percentage of NAs in each column
NAs <- sapply(dat_fct, function(df){
sum(is.na(df) ==TRUE)/length(df);
})
# remove columns with more than 5 % NAs
dat_fct <- dat_fct[, -which(NAs > 0.05)]
# convert factor columns to numerical
dat_fct$BRAF <- ifelse(dat_fct$BRAF == "pos", 1, 0)
dat_fct$Stadium <- ifelse(dat_fct$Stadium == "II", 2,ifelse(dat_fct$Stadium == "III", 3, 4))
# impute missing values with random forest algorithm
set.seed(25)
dat_imp <- dat_fct %>%
select_if(is.numeric) %>%
as.data.frame() %>%
missForest() %>%
.$ximp %>%
# replace calculated probabilities by the factor
mutate(BRAF = ifelse(BRAF > 0.5, 1,0),
Stadium = round(Stadium))
# replace numerical values by factor for encoding later
dat_imp$BRAF <- factor(dat_imp$BRAF, levels = c(0,1), labels = c("neg", "pos"))
dat_imp$Stadium <- factor(dat_imp$Stadium, levels = c(2,3,4), labels = c("II", "III", "IV"))
# replacing NAs with imputed values
dat_fct$BRAF <- dat_imp$BRAF
dat_fct$Stadium <- dat_imp$Stadium
dat_fct$S100 <- dat_imp$S100
set.seed(4)
resample <- dat_fct[sample(nrow(dat_fct), replace = TRUE), ]
# define test and training set
set.seed(123)
ind.train <- createDataPartition(resample$Responder, p = 0.7, list = FALSE)
train.data  <- resample[ind.train, ]
test.data <- resample[-ind.train, ]
# transform training data
tmp.train <- train.data %>% select(where(is.numeric))
fctrs <- train.data %>% select(!where(is.numeric))
train <- data.frame(cbind(log(tmp.train  + 1), fctrs))
# transform testing data
tmp.test  <- test.data %>% select(where(is.numeric))
fctrs <- test.data %>% select(!where(is.numeric))
test <- data.frame(cbind(log(tmp.test  + 1), fctrs))
# dummy encoding of factors with model.matrix
x.train <- model.matrix(Responder~.,data=train)[,-1]
y.train <- train$Responder
# dummy encoding of factors with model.matrix for test set
x.test <- model.matrix(Responder~.,data=test)[,-1]
y.test <- test$Responder
cl <- makeCluster(detectCores(), type='PSOCK')
registerDoParallel(cl)
# define ctrl function
cctrl1 <- trainControl(method="cv", number=10, returnResamp="all",
classProbs=TRUE, summaryFunction=twoClassSummary)
# run glmnet model
set.seed(849)
md <- train(x.train, y.train, method = "glmnet",preProcess = c("center","scale"),
trControl = cctrl1,metric = "ROC",tuneGrid = expand.grid(alpha = seq(0,1,0.1),
lambda = seq(0.001,0.2,by = 0.001)))
max(md$results$ROC)
coef(md$finalModel, md$finalModel$lambdaOpt)
pred <- md %>% predict(x.test, type = "prob")
obs <- y.test
roc_obj <- roc(obs, pred$ja)
auc(roc_obj)
x <- model.matrix(Responder~.,data=dat_fct)[,-1]
y <- ifelse(dat_fct$Responder == "ja", 1,0)
boot_auc(y, x, B = 10, learner = "glm_wrapper")
install.packages("nlpred")
library(nlpred)
install.packages("htmltools")
library(nlpred)
boot_auc(y, x, B = 10, learner = "glm_wrapper")
boot_auc(y, x, B = 20, learner = "glm_wrapper")
boot_auc(y, x, B = 100, learner = "glm_wrapper")
boot_auc(y, x, B = 500, learner = "glm_wrapper")
?boot_auc
?glm_wrapper
boot_auc(y, x, B = 10, learner = "glmnet_wrapper")
set.seed(849)
md <- train(x, dat_fct$Responder, method = "glmnet",preProcess = c("center","scale"),
trControl = cctrl1,metric = "ROC",tuneGrid = expand.grid(alpha = seq(0,1,0.1),
lambda = seq(0.001,0.2,by = 0.001)))
max(md$results$ROC)
coef(md$finalModel, md$finalModel$lambdaOpt)
